{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f90b2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ODR - Organized Data Research System\n",
    "# Complete implementation with interactive clarification, intelligent supervisor, and multi-model support\n",
    "\n",
    "# Cell 1: Dependencies and Configuration\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import sqlite3\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class ResearchPlan:\n",
    "    topic: str\n",
    "    introduction: str\n",
    "    sections: List[str]\n",
    "    conclusion: str\n",
    "    citations: List[str]\n",
    "    \n",
    "class DataSource(Enum):\n",
    "    WEB_SEARCH = \"web_search\"\n",
    "    INTERNAL_MCP = \"internal_mcp\"\n",
    "    HYBRID = \"hybrid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a5d584c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Multi-Model LLM Client\n",
    "class MultiModelLLMClient:\n",
    "    \"\"\"Supports different models for different tasks\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'clarification': 'gpt-4-turbo',  # Good for interactive dialogue\n",
    "            'planning': 'gpt-4',             # Good for structured planning\n",
    "            'research': 'gpt-4-turbo',       # Good for tool calling\n",
    "            'writing': 'claude-3-opus',      # Excellent for long-form writing\n",
    "            'evaluation': 'gpt-4'            # Good for decision making\n",
    "        }\n",
    "        self.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    \n",
    "    def chat(self, prompt: str, task_type: str = 'general', temperature: float = 0.7) -> str:\n",
    "        \"\"\"Mock implementation - replace with actual API calls\"\"\"\n",
    "        \n",
    "        # Simulate different model behaviors based on task type\n",
    "        if task_type == 'clarification':\n",
    "            return self._handle_clarification(prompt)\n",
    "        elif task_type == 'planning':\n",
    "            return self._handle_planning(prompt)\n",
    "        elif task_type == 'research':\n",
    "            return self._handle_research(prompt)\n",
    "        elif task_type == 'writing':\n",
    "            return self._handle_writing(prompt)\n",
    "        elif task_type == 'evaluation':\n",
    "            return self._handle_evaluation(prompt)\n",
    "        else:\n",
    "            return \"[Generic LLM Response]\"\n",
    "    \n",
    "    def _handle_clarification(self, prompt: str) -> str:\n",
    "        \"\"\"Simulate clarification responses\"\"\"\n",
    "        clarification_responses = {\n",
    "            \"quantum computing encryption\": {\n",
    "                \"clarified\": True,\n",
    "                \"topic\": \"The impact of quantum computing on current encryption standards and the development of post-quantum cryptography\",\n",
    "                \"questions\": []\n",
    "            },\n",
    "            \"ai ethics\": {\n",
    "                \"clarified\": False,\n",
    "                \"topic\": \"AI Ethics\",\n",
    "                \"questions\": [\n",
    "                    \"Are you interested in AI ethics in healthcare, autonomous vehicles, or general applications?\",\n",
    "                    \"Do you want to focus on current ethical frameworks or emerging challenges?\",\n",
    "                    \"What specific aspects: bias, privacy, accountability, or transparency?\"\n",
    "                ]\n",
    "            },\n",
    "            \"climate change\": {\n",
    "                \"clarified\": False,\n",
    "                \"topic\": \"Climate Change\",\n",
    "                \"questions\": [\n",
    "                    \"Which aspect of climate change: impacts, mitigation strategies, or adaptation measures?\",\n",
    "                    \"Are you looking at global trends or specific regional effects?\",\n",
    "                    \"Time frame of interest: current situation, projections, or historical analysis?\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Simple keyword matching for demo\n",
    "        for key, response in clarification_responses.items():\n",
    "            if key in prompt.lower():\n",
    "                return json.dumps(response)\n",
    "        \n",
    "        # Default response for unknown topics\n",
    "        return json.dumps({\n",
    "            \"clarified\": False,\n",
    "            \"topic\": \"Research Topic\",\n",
    "            \"questions\": [\n",
    "                \"Could you provide more specific details about what aspects you'd like to research?\",\n",
    "                \"What is the intended use or audience for this research?\",\n",
    "                \"Are there any particular angles or perspectives you want to focus on?\"\n",
    "            ]\n",
    "        })\n",
    "    \n",
    "    def _handle_planning(self, prompt: str) -> str:\n",
    "        \"\"\"Generate structured research plans\"\"\"\n",
    "        if \"quantum computing\" in prompt.lower():\n",
    "            return json.dumps({\n",
    "                \"introduction\": \"Overview of quantum computing's revolutionary impact on cryptography and data security\",\n",
    "                \"sections\": [\n",
    "                    \"Fundamentals of Quantum Computing\",\n",
    "                    \"Current Encryption Standards and Vulnerabilities\", \n",
    "                    \"Quantum Algorithms and Cryptographic Threats\",\n",
    "                    \"Post-Quantum Cryptography Solutions\",\n",
    "                    \"Implementation Challenges and Timeline\",\n",
    "                    \"Industry and Government Response\"\n",
    "                ],\n",
    "                \"conclusion\": \"Assessment of the cryptographic landscape transition and future security implications\",\n",
    "                \"citations\": [\n",
    "                    \"NIST Post-Quantum Cryptography Standards\",\n",
    "                    \"Shor's Algorithm and RSA Vulnerability\",\n",
    "                    \"Current Quantum Computer Capabilities\"\n",
    "                ]\n",
    "            })\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"introduction\": \"Comprehensive analysis of the research topic\",\n",
    "            \"sections\": [\"Background\", \"Current State\", \"Analysis\", \"Implications\"],\n",
    "            \"conclusion\": \"Summary of findings and future considerations\",\n",
    "            \"citations\": [\"Academic sources\", \"Industry reports\", \"Expert opinions\"]\n",
    "        })\n",
    "    \n",
    "    def _handle_research(self, prompt: str) -> str:\n",
    "        \"\"\"Handle research-related queries\"\"\"\n",
    "        return \"[Research findings and analysis]\"\n",
    "    \n",
    "    def _handle_writing(self, prompt: str) -> str:\n",
    "        \"\"\"Generate well-structured written content\"\"\"\n",
    "        if \"quantum computing\" in prompt.lower():\n",
    "            return \"\"\"# Quantum Computing and Encryption: A Comprehensive Analysis\n",
    "\n",
    "## Introduction\n",
    "Quantum computing represents one of the most significant technological advances of the 21st century, with profound implications for digital security and cryptography. As quantum computers evolve from theoretical concepts to practical reality, they pose both unprecedented opportunities and existential threats to our current cryptographic infrastructure.\n",
    "\n",
    "## Fundamentals of Quantum Computing\n",
    "Quantum computers leverage the principles of quantum mechanics‚Äîsuperposition, entanglement, and quantum interference‚Äîto process information in ways that classical computers cannot. Unlike classical bits that exist in definite states of 0 or 1, quantum bits (qubits) can exist in superposition, representing both states simultaneously.\n",
    "\n",
    "## Current Encryption Standards and Vulnerabilities\n",
    "Modern encryption relies heavily on mathematical problems that are computationally infeasible for classical computers to solve, such as integer factorization (RSA) and discrete logarithms (ECC). These form the backbone of internet security, protecting everything from online banking to private communications.\n",
    "\n",
    "## Quantum Algorithms and Cryptographic Threats\n",
    "Shor's algorithm, developed by mathematician Peter Shor in 1994, demonstrates how a sufficiently powerful quantum computer could efficiently factor large integers and solve discrete logarithm problems. This breakthrough would render current public-key cryptography obsolete virtually overnight.\n",
    "\n",
    "## Post-Quantum Cryptography Solutions\n",
    "The cryptographic community has responded by developing quantum-resistant algorithms based on mathematical problems believed to be hard even for quantum computers. These include lattice-based, hash-based, code-based, and multivariate cryptographic schemes.\n",
    "\n",
    "## Implementation Challenges and Timeline\n",
    "Transitioning to post-quantum cryptography presents significant challenges: performance overhead, key size increases, standardization processes, and the massive scale of infrastructure that must be updated.\n",
    "\n",
    "## Industry and Government Response\n",
    "Governments and organizations worldwide are taking the quantum threat seriously. NIST has been leading standardization efforts, while companies are beginning quantum risk assessments and migration planning.\n",
    "\n",
    "## Conclusion\n",
    "The advent of quantum computing necessitates a fundamental shift in how we approach digital security. While the timeline for cryptographically relevant quantum computers remains uncertain, the transition to quantum-resistant cryptography must begin now to ensure continued security in the quantum era.\n",
    "\n",
    "## References\n",
    "1. NIST Post-Quantum Cryptography Standardization Process\n",
    "2. Shor, P.W. \"Polynomial-Time Algorithms for Prime Factorization\"\n",
    "3. Current capabilities of quantum computers from IBM, Google, and other providers\"\"\"\n",
    "        \n",
    "        return \"[Comprehensive written report based on research findings]\"\n",
    "    \n",
    "    def _handle_evaluation(self, prompt: str) -> str:\n",
    "        \"\"\"Make intelligent decisions about data sources and research strategies\"\"\"\n",
    "        return json.dumps({\n",
    "            \"decision\": \"internal_mcp\",\n",
    "            \"confidence\": 0.85,\n",
    "            \"reasoning\": \"Internal data sources contain relevant recent analysis on this topic\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ebd1a393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchTool:\n",
    "    \"\"\"Enhanced web search with real API integration capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.tavily.com/search\"\n",
    "    \n",
    "    def search(self, query: str, max_results: int = 5) -> Dict[str, Any]:\n",
    "        \"\"\"Perform web search and return structured results\"\"\"\n",
    "        \n",
    "        # Mock implementation - replace with actual API call\n",
    "        mock_results = {\n",
    "            \"quantum computing encryption\": {\n",
    "                \"results\": [\n",
    "                    {\n",
    "                        \"title\": \"NIST Announces Post-Quantum Cryptography Standards\",\n",
    "                        \"url\": \"https://nist.gov/news/pqc-standards-2024\",\n",
    "                        \"content\": \"NIST has released the first set of post-quantum cryptography standards...\",\n",
    "                        \"relevance_score\": 0.95\n",
    "                    },\n",
    "                    {\n",
    "                        \"title\": \"IBM's Latest Quantum Computer Capabilities\",\n",
    "                        \"url\": \"https://ibm.com/quantum/news\",\n",
    "                        \"content\": \"IBM's new quantum processor demonstrates significant advances...\",\n",
    "                        \"relevance_score\": 0.88\n",
    "                    }\n",
    "                ],\n",
    "                \"total_results\": 2,\n",
    "                \"search_time\": 0.45\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Simple keyword matching for demo\n",
    "        for key, results in mock_results.items():\n",
    "            if any(term in query.lower() for term in key.split()):\n",
    "                return results\n",
    "        \n",
    "        # Default response\n",
    "        return {\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"title\": f\"Search Results for: {query}\",\n",
    "                    \"url\": \"https://example.com/search\",\n",
    "                    \"content\": f\"Relevant information about {query}...\",\n",
    "                    \"relevance_score\": 0.75\n",
    "                }\n",
    "            ],\n",
    "            \"total_results\": 1,\n",
    "            \"search_time\": 0.3\n",
    "        }\n",
    "    \n",
    "    def get_page_content(self, url: str) -> str:\n",
    "        \"\"\"Fetch full content from a specific URL\"\"\"\n",
    "        return f\"[Full page content from {url}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "54402066",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPTool:\n",
    "    \"\"\"Enhanced MCP tool with multiple data source support\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.data_sources = {\n",
    "            'filesystem': self._init_filesystem(),\n",
    "            'database': self._init_database(),\n",
    "            'mongodb': self._init_mongodb()\n",
    "        }\n",
    "    \n",
    "    def _init_filesystem(self) -> Dict:\n",
    "        \"\"\"Initialize filesystem data source\"\"\"\n",
    "        return {\n",
    "            'connected': True,\n",
    "            'available_topics': [\n",
    "                'quantum_computing_research.pdf',\n",
    "                'encryption_standards_2024.md',\n",
    "                'post_quantum_crypto_analysis.json'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _init_database(self) -> Dict:\n",
    "        \"\"\"Initialize SQL database connection\"\"\"\n",
    "        return {\n",
    "            'connected': True,\n",
    "            'tables': ['research_papers', 'citations', 'expert_opinions'],\n",
    "            'recent_updates': '2024-07-20'\n",
    "        }\n",
    "    \n",
    "    def _init_mongodb(self) -> Dict:\n",
    "        \"\"\"Initialize MongoDB connection\"\"\"\n",
    "        return {\n",
    "            'connected': True,\n",
    "            'collections': ['research_data', 'web_scrapes', 'analysis_cache'],\n",
    "            'document_count': 15420\n",
    "        }\n",
    "    \n",
    "    def evaluate_data_availability(self, topic: str) -> Dict[str, Any]:\n",
    "        \"\"\"Intelligently evaluate what data is available for a topic\"\"\"\n",
    "        \n",
    "        # Simulate intelligent evaluation\n",
    "        evaluations = {\n",
    "            \"quantum computing\": {\n",
    "                \"filesystem\": {\"available\": True, \"quality\": 0.9, \"recency\": 0.8},\n",
    "                \"database\": {\"available\": True, \"quality\": 0.85, \"recency\": 0.7},\n",
    "                \"mongodb\": {\"available\": True, \"quality\": 0.8, \"recency\": 0.9}\n",
    "            },\n",
    "            \"encryption\": {\n",
    "                \"filesystem\": {\"available\": True, \"quality\": 0.95, \"recency\": 0.9},\n",
    "                \"database\": {\"available\": True, \"quality\": 0.9, \"recency\": 0.8},\n",
    "                \"mongodb\": {\"available\": False, \"quality\": 0.0, \"recency\": 0.0}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Check for topic matches\n",
    "        for key, eval_data in evaluations.items():\n",
    "            if key in topic.lower():\n",
    "                return {\n",
    "                    \"has_data\": True,\n",
    "                    \"sources\": eval_data,\n",
    "                    \"recommended_source\": max(eval_data.keys(), \n",
    "                                           key=lambda x: eval_data[x][\"quality\"] * eval_data[x][\"recency\"])\n",
    "                }\n",
    "        \n",
    "        return {\n",
    "            \"has_data\": False,\n",
    "            \"sources\": {},\n",
    "            \"recommended_source\": None\n",
    "        }\n",
    "    \n",
    "    def query_data(self, topic: str, source: str = \"auto\") -> Dict[str, Any]:\n",
    "        \"\"\"Query internal data sources\"\"\"\n",
    "        \n",
    "        if source == \"auto\":\n",
    "            evaluation = self.evaluate_data_availability(topic)\n",
    "            if evaluation[\"has_data\"]:\n",
    "                source = evaluation[\"recommended_source\"]\n",
    "            else:\n",
    "                return {\"error\": \"No internal data available for this topic\"}\n",
    "        \n",
    "        # Mock data retrieval\n",
    "        mock_data = {\n",
    "            \"quantum computing\": {\n",
    "                \"summary\": \"Comprehensive analysis of quantum computing impact on cryptography\",\n",
    "                \"key_points\": [\n",
    "                    \"Shor's algorithm threatens current RSA encryption\",\n",
    "                    \"Post-quantum cryptography development is accelerating\",\n",
    "                    \"NIST standardization process nearing completion\"\n",
    "                ],\n",
    "                \"data_quality\": 0.92,\n",
    "                \"last_updated\": \"2024-07-15\"\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for key, data in mock_data.items():\n",
    "            if key in topic.lower():\n",
    "                return data\n",
    "        \n",
    "        return {\"summary\": f\"Internal data analysis for {topic}\", \"data_quality\": 0.75}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3a53d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserClarificationModule:\n",
    "    \"\"\"Handles interactive user clarification with gap identification\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: MultiModelLLMClient):\n",
    "        self.llm = llm_client\n",
    "        self.max_clarification_rounds = 3\n",
    "    \n",
    "    def clarify_user_input(self, initial_input: str) -> Tuple[str, bool]:\n",
    "        \"\"\"Interactive clarification process\"\"\"\n",
    "        \n",
    "        current_input = initial_input\n",
    "        clarification_round = 0\n",
    "        \n",
    "        print(f\"üîç Starting clarification for: '{initial_input}'\")\n",
    "        \n",
    "        while clarification_round < self.max_clarification_rounds:\n",
    "            # Get clarification assessment\n",
    "            clarification_prompt = f\"\"\"\n",
    "            Analyze this research topic and determine if it needs clarification: \"{current_input}\"\n",
    "            \n",
    "            Respond with JSON containing:\n",
    "            - \"clarified\": boolean indicating if topic is sufficiently clear\n",
    "            - \"topic\": refined version of the topic\n",
    "            - \"questions\": list of specific questions to ask user if clarification needed\n",
    "            \"\"\"\n",
    "            \n",
    "            response = self.llm.chat(clarification_prompt, task_type='clarification')\n",
    "            clarification_data = json.loads(response)\n",
    "            \n",
    "            if clarification_data[\"clarified\"]:\n",
    "                print(f\"‚úÖ Topic clarified: {clarification_data['topic']}\")\n",
    "                return clarification_data[\"topic\"], True\n",
    "            \n",
    "            # Ask clarification questions\n",
    "            print(f\"\\nüìù Clarification needed (Round {clarification_round + 1}):\")\n",
    "            for i, question in enumerate(clarification_data[\"questions\"], 1):\n",
    "                print(f\"   {i}. {question}\")\n",
    "            \n",
    "            # Simulate user responses (in real implementation, get actual user input)\n",
    "            user_responses = self._simulate_user_responses(clarification_data[\"questions\"], current_input)\n",
    "            \n",
    "            # Update input based on responses\n",
    "            current_input = self._integrate_responses(current_input, user_responses)\n",
    "            clarification_round += 1\n",
    "        \n",
    "        print(f\"‚ö†Ô∏è  Maximum clarification rounds reached. Proceeding with: {current_input}\")\n",
    "        return current_input, False\n",
    "    \n",
    "    def _simulate_user_responses(self, questions: List[str], topic: str) -> List[str]:\n",
    "        \"\"\"Simulate user responses to clarification questions\"\"\"\n",
    "        \n",
    "        # Mock responses based on topic\n",
    "        if \"quantum computing\" in topic.lower():\n",
    "            return [\n",
    "                \"Focus on impact on current encryption standards\",\n",
    "                \"Include both technical and business implications\",\n",
    "                \"Cover the timeline for quantum threat realization\"\n",
    "            ]\n",
    "        elif \"ai ethics\" in topic.lower():\n",
    "            return [\n",
    "                \"General AI applications across industries\",\n",
    "                \"Current ethical frameworks and emerging challenges\",\n",
    "                \"Focus on bias and accountability issues\"\n",
    "            ]\n",
    "        \n",
    "        return [\"Provide comprehensive coverage\", \"Include recent developments\", \"Focus on practical implications\"]\n",
    "    \n",
    "    def _integrate_responses(self, original_input: str, responses: List[str]) -> str:\n",
    "        \"\"\"Integrate user responses into refined topic\"\"\"\n",
    "        \n",
    "        integration_prompt = f\"\"\"\n",
    "        Original research topic: \"{original_input}\"\n",
    "        User clarifications: {json.dumps(responses)}\n",
    "        \n",
    "        Create a refined, specific research topic that incorporates the user's clarifications.\n",
    "        \"\"\"\n",
    "        \n",
    "        # For demo, create refined topics based on responses\n",
    "        if \"quantum computing\" in original_input.lower():\n",
    "            return \"Impact of quantum computing on current encryption standards: technical capabilities, business implications, and implementation timeline\"\n",
    "        \n",
    "        return f\"{original_input} - {', '.join(responses[:2])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c982ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchPlanGenerator:\n",
    "    \"\"\"Generates comprehensive research plans\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: MultiModelLLMClient):\n",
    "        self.llm = llm_client\n",
    "    \n",
    "    def generate_plan(self, clarified_topic: str) -> ResearchPlan:\n",
    "        \"\"\"Generate detailed research plan\"\"\"\n",
    "        \n",
    "        print(f\"üìã Generating research plan for: {clarified_topic}\")\n",
    "        \n",
    "        planning_prompt = f\"\"\"\n",
    "        Create a comprehensive research plan for: \"{clarified_topic}\"\n",
    "        \n",
    "        Generate a detailed JSON response with:\n",
    "        - \"introduction\": Brief overview of what will be covered\n",
    "        - \"sections\": List of 4-8 specific research sections\n",
    "        - \"conclusion\": What the conclusion should address\n",
    "        - \"citations\": List of key types of sources to find\n",
    "        \n",
    "        Make the plan specific, actionable, and comprehensive.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.llm.chat(planning_prompt, task_type='planning')\n",
    "        plan_data = json.loads(response)\n",
    "        \n",
    "        research_plan = ResearchPlan(\n",
    "            topic=clarified_topic,\n",
    "            introduction=plan_data[\"introduction\"],\n",
    "            sections=plan_data[\"sections\"],\n",
    "            conclusion=plan_data[\"conclusion\"],\n",
    "            citations=plan_data[\"citations\"]\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Research plan generated with {len(research_plan.sections)} sections\")\n",
    "        self._display_plan(research_plan)\n",
    "        \n",
    "        return research_plan\n",
    "    \n",
    "    def _display_plan(self, plan: ResearchPlan):\n",
    "        \"\"\"Display the research plan\"\"\"\n",
    "        print(\"\\nüìä Research Plan Overview:\")\n",
    "        print(f\"Introduction: {plan.introduction}\")\n",
    "        print(\"\\nSections:\")\n",
    "        for i, section in enumerate(plan.sections, 1):\n",
    "            print(f\"  {i}. {section}\")\n",
    "        print(f\"\\nConclusion Focus: {plan.conclusion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "03242cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchSupervisor:\n",
    "    \"\"\"Intelligent supervisor that decides optimal research strategy\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: MultiModelLLMClient, web_tool: WebSearchTool, mcp_tool: MCPTool):\n",
    "        self.llm = llm_client\n",
    "        self.web_tool = web_tool\n",
    "        self.mcp_tool = mcp_tool\n",
    "        self.research_findings = {}\n",
    "    \n",
    "    def execute_research(self, plan: ResearchPlan) -> Dict[str, Any]:\n",
    "        \"\"\"Execute research according to the plan using intelligent source selection\"\"\"\n",
    "        \n",
    "        print(f\"üî¨ Starting research execution with {len(plan.sections)} sections\")\n",
    "        \n",
    "        for i, section in enumerate(plan.sections, 1):\n",
    "            print(f\"\\nüìñ Researching Section {i}: {section}\")\n",
    "            \n",
    "            # Intelligent source selection\n",
    "            data_source = self._select_optimal_source(section)\n",
    "            \n",
    "            # Execute research based on selected source\n",
    "            if data_source == DataSource.INTERNAL_MCP:\n",
    "                findings = self._research_internal(section)\n",
    "            elif data_source == DataSource.WEB_SEARCH:\n",
    "                findings = self._research_web(section)\n",
    "            else:  # HYBRID\n",
    "                findings = self._research_hybrid(section)\n",
    "            \n",
    "            self.research_findings[section] = findings\n",
    "            \n",
    "            # Brief pause to simulate processing time\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Research completed for all {len(plan.sections)} sections\")\n",
    "        return self.research_findings\n",
    "    \n",
    "    def _select_optimal_source(self, section: str) -> DataSource:\n",
    "        \"\"\"Intelligently select the best data source for each section\"\"\"\n",
    "        \n",
    "        # Evaluate internal data availability\n",
    "        mcp_evaluation = self.mcp_tool.evaluate_data_availability(section)\n",
    "        \n",
    "        # Use LLM to make intelligent decision\n",
    "        decision_prompt = f\"\"\"\n",
    "        Research section: \"{section}\"\n",
    "        Internal data availability: {json.dumps(mcp_evaluation)}\n",
    "        \n",
    "        Decide the best research approach:\n",
    "        - \"internal_mcp\": Use internal data sources (high quality, may be limited scope)\n",
    "        - \"web_search\": Use web search (broad coverage, may need filtering)\n",
    "        - \"hybrid\": Use both sources for comprehensive coverage\n",
    "        \n",
    "        Respond with JSON containing:\n",
    "        - \"decision\": one of the above options\n",
    "        - \"confidence\": confidence score 0-1\n",
    "        - \"reasoning\": brief explanation of decision\n",
    "        \"\"\"\n",
    "        \n",
    "        response = self.llm.chat(decision_prompt, task_type='evaluation')\n",
    "        decision_data = json.loads(response)\n",
    "        \n",
    "        decision_map = {\n",
    "            \"internal_mcp\": DataSource.INTERNAL_MCP,\n",
    "            \"web_search\": DataSource.WEB_SEARCH,\n",
    "            \"hybrid\": DataSource.HYBRID\n",
    "        }\n",
    "        \n",
    "        selected_source = decision_map.get(decision_data[\"decision\"], DataSource.WEB_SEARCH)\n",
    "        \n",
    "        print(f\"   üéØ Selected source: {selected_source.value} (confidence: {decision_data['confidence']:.2f})\")\n",
    "        print(f\"   üìù Reasoning: {decision_data['reasoning']}\")\n",
    "        \n",
    "        return selected_source\n",
    "    \n",
    "    def _research_internal(self, section: str) -> Dict[str, Any]:\n",
    "        \"\"\"Research using internal MCP sources\"\"\"\n",
    "        \n",
    "        print(f\"   üè† Using internal data sources...\")\n",
    "        \n",
    "        data = self.mcp_tool.query_data(section)\n",
    "        \n",
    "        return {\n",
    "            \"source_type\": \"internal\",\n",
    "            \"data\": data,\n",
    "            \"quality_score\": data.get(\"data_quality\", 0.8),\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "    \n",
    "    def _research_web(self, section: str) -> Dict[str, Any]:\n",
    "        \"\"\"Research using web search\"\"\"\n",
    "        \n",
    "        print(f\"   üåê Using web search...\")\n",
    "        \n",
    "        search_results = self.web_tool.search(section)\n",
    "        \n",
    "        return {\n",
    "            \"source_type\": \"web\",\n",
    "            \"data\": search_results,\n",
    "            \"quality_score\": 0.75,  # Web results need more validation\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "    \n",
    "    def _research_hybrid(self, section: str) -> Dict[str, Any]:\n",
    "        \"\"\"Research using both internal and web sources\"\"\"\n",
    "        \n",
    "        print(f\"   üîÑ Using hybrid approach (internal + web)...\")\n",
    "        \n",
    "        internal_data = self.mcp_tool.query_data(section)\n",
    "        web_data = self.web_tool.search(section)\n",
    "        \n",
    "        return {\n",
    "            \"source_type\": \"hybrid\",\n",
    "            \"data\": {\n",
    "                \"internal\": internal_data,\n",
    "                \"web\": web_data\n",
    "            },\n",
    "            \"quality_score\": 0.9,  # Hybrid approach provides best coverage\n",
    "            \"timestamp\": time.time()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64cfee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportGenerator:\n",
    "    \"\"\"Generates comprehensive final reports using specialized writing models\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_client: MultiModelLLMClient):\n",
    "        self.llm = llm_client\n",
    "    \n",
    "    def generate_final_report(self, plan: ResearchPlan, findings: Dict[str, Any]) -> str:\n",
    "        \"\"\"Generate comprehensive final report\"\"\"\n",
    "        \n",
    "        print(\"üìù Generating final research report...\")\n",
    "        \n",
    "        # Prepare research context\n",
    "        context = self._prepare_research_context(plan, findings)\n",
    "        \n",
    "        # Generate report using specialized writing model\n",
    "        report_prompt = f\"\"\"\n",
    "        Generate a comprehensive research report based on the following:\n",
    "        \n",
    "        Research Plan:\n",
    "        Topic: {plan.topic}\n",
    "        Introduction: {plan.introduction}\n",
    "        Sections: {json.dumps(plan.sections)}\n",
    "        Conclusion Focus: {plan.conclusion}\n",
    "        \n",
    "        Research Findings:\n",
    "        {json.dumps(context, indent=2)}\n",
    "        \n",
    "        Create a well-structured, professional research report with:\n",
    "        - Executive summary\n",
    "        - Detailed sections based on the research plan\n",
    "        - Proper citations and references\n",
    "        - Data-driven insights and analysis\n",
    "        - Clear conclusions and recommendations\n",
    "        \n",
    "        Format as markdown with proper headings and structure.\n",
    "        \"\"\"\n",
    "        \n",
    "        report = self.llm.chat(report_prompt, task_type='writing', temperature=0.3)\n",
    "        \n",
    "        print(\"‚úÖ Final report generated successfully\")\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _prepare_research_context(self, plan: ResearchPlan, findings: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Prepare research context for report generation\"\"\"\n",
    "        \n",
    "        context = {\n",
    "            \"sections_data\": {},\n",
    "            \"source_summary\": {\"internal\": 0, \"web\": 0, \"hybrid\": 0},\n",
    "            \"quality_metrics\": []\n",
    "        }\n",
    "        \n",
    "        for section, data in findings.items():\n",
    "            context[\"sections_data\"][section] = {\n",
    "                \"source_type\": data[\"source_type\"],\n",
    "                \"summary\": str(data[\"data\"])[:200] + \"...\",  # Truncate for context\n",
    "                \"quality\": data[\"quality_score\"]\n",
    "            }\n",
    "            \n",
    "            # Update source summary\n",
    "            context[\"source_summary\"][data[\"source_type\"]] += 1\n",
    "            context[\"quality_metrics\"].append(data[\"quality_score\"])\n",
    "        \n",
    "        # Calculate average quality\n",
    "        if context[\"quality_metrics\"]:\n",
    "            context[\"average_quality\"] = sum(context[\"quality_metrics\"]) / len(context[\"quality_metrics\"])\n",
    "        \n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffd6f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODRPipeline:\n",
    "    \"\"\"Main orchestrator for the ODR system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = MultiModelLLMClient()\n",
    "        self.web_tool = WebSearchTool(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "        self.mcp_tool = MCPTool()\n",
    "        \n",
    "        # Initialize modules\n",
    "        self.clarification_module = UserClarificationModule(self.llm)\n",
    "        self.plan_generator = ResearchPlanGenerator(self.llm)\n",
    "        self.research_supervisor = ResearchSupervisor(self.llm, self.web_tool, self.mcp_tool)\n",
    "        self.report_generator = ReportGenerator(self.llm)\n",
    "    \n",
    "    def execute_research_pipeline(self, user_input: str) -> Tuple[str, Dict[str, Any]]:\n",
    "        \"\"\"Execute the complete ODR pipeline\"\"\"\n",
    "        \n",
    "        print(\"üöÄ Starting ODR Pipeline\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Module 1: Clarify user input\n",
    "        print(\"\\nüìã MODULE 1: User Input Clarification\")\n",
    "        clarified_topic, fully_clarified = self.clarification_module.clarify_user_input(user_input)\n",
    "        \n",
    "        # Module 2: Generate research plan\n",
    "        print(\"\\nüìä MODULE 2: Research Plan Generation\")\n",
    "        research_plan = self.plan_generator.generate_plan(clarified_topic)\n",
    "        \n",
    "        # Module 3: Execute research with supervisor\n",
    "        print(\"\\nüî¨ MODULE 3: Research Execution\")\n",
    "        research_findings = self.research_supervisor.execute_research(research_plan)\n",
    "        \n",
    "        # Final Step: Generate report\n",
    "        print(\"\\nüìù FINAL STEP: Report Generation\")\n",
    "        final_report = self.report_generator.generate_final_report(research_plan, research_findings)\n",
    "        \n",
    "        # Compile metadata\n",
    "        metadata = {\n",
    "            \"original_input\": user_input,\n",
    "            \"clarified_topic\": clarified_topic,\n",
    "            \"fully_clarified\": fully_clarified,\n",
    "            \"research_plan\": research_plan,\n",
    "            \"findings_summary\": {\n",
    "                \"total_sections\": len(research_findings),\n",
    "                \"source_distribution\": self._analyze_source_distribution(research_findings),\n",
    "                \"average_quality\": self._calculate_average_quality(research_findings)\n",
    "            },\n",
    "            \"pipeline_timestamp\": time.time()\n",
    "        }\n",
    "        \n",
    "        print(\"\\n‚úÖ ODR Pipeline completed successfully!\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        return final_report, metadata\n",
    "    \n",
    "    def _analyze_source_distribution(self, findings: Dict[str, Any]) -> Dict[str, int]:\n",
    "        \"\"\"Analyze distribution of data sources used\"\"\"\n",
    "        distribution = {\"internal\": 0, \"web\": 0, \"hybrid\": 0}\n",
    "        \n",
    "        for data in findings.values():\n",
    "            source_type = data.get(\"source_type\", \"unknown\")\n",
    "            if source_type in distribution:\n",
    "                distribution[source_type] += 1\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def _calculate_average_quality(self, findings: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate average quality score across all findings\"\"\"\n",
    "        quality_scores = [data.get(\"quality_score\", 0) for data in findings.values()]\n",
    "        return sum(quality_scores) / len(quality_scores) if quality_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "90f282c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_odr_demo():\n",
    "    \"\"\"Run demonstration of the ODR system\"\"\"\n",
    "    \n",
    "    # Initialize ODR pipeline\n",
    "    odr = ODRPipeline()\n",
    "    \n",
    "    # Test cases\n",
    "    test_cases = [\n",
    "        \"What are the implications of quantum computing on encryption?\",\n",
    "        \"AI ethics in healthcare\",\n",
    "        \"Climate change impact on agriculture\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üß™ ODR System Demonstration\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, test_input in enumerate(test_cases, 1):\n",
    "        print(f\"\\nüîç TEST CASE {i}: {test_input}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            # Execute pipeline\n",
    "            report, metadata = odr.execute_research_pipeline(test_input)\n",
    "            \n",
    "            # Display results summary\n",
    "            print(f\"\\nüìä RESULTS SUMMARY:\")\n",
    "            print(f\"Original Input: {metadata['original_input']}\")\n",
    "            print(f\"Clarified Topic: {metadata['clarified_topic']}\")\n",
    "            print(f\"Sections Researched: {metadata['findings_summary']['total_sections']}\")\n",
    "            print(f\"Source Distribution: {metadata['findings_summary']['source_distribution']}\")\n",
    "            print(f\"Average Quality Score: {metadata['findings_summary']['average_quality']:.2f}\")\n",
    "            \n",
    "            # Display first part of report\n",
    "            print(f\"\\nüìÑ REPORT PREVIEW:\")\n",
    "            report_preview = report[:500] + \"...\" if len(report) > 500 else report\n",
    "            print(report_preview)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error in test case {i}: {str(e)}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "    \n",
    "    return \"Demo completed successfully!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "446ec7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_environment():\n",
    "    \"\"\"Setup environment and validate configuration\"\"\"\n",
    "    \n",
    "    print(\"üîß Setting up ODR environment...\")\n",
    "    \n",
    "    # Check required environment variables\n",
    "    required_vars = [\"OPENAI_API_KEY\", \"TAVILY_API_KEY\"]\n",
    "    missing_vars = []\n",
    "    \n",
    "    for var in required_vars:\n",
    "        if not os.getenv(var):\n",
    "            missing_vars.append(var)\n",
    "    \n",
    "    if missing_vars:\n",
    "        print(f\"‚ö†Ô∏è  Warning: Missing environment variables: {missing_vars}\")\n",
    "        print(\"   Create a .env file with your API keys for full functionality\")\n",
    "    else:\n",
    "        print(\"‚úÖ All environment variables configured\")\n",
    "    \n",
    "    # Test data source connections\n",
    "    print(\"\\nüîå Testing data source connections...\")\n",
    "    \n",
    "    try:\n",
    "        # Test MCP tool\n",
    "        mcp = MCPTool()\n",
    "        print(\"‚úÖ MCP tool initialized successfully\")\n",
    "        \n",
    "        # Test web search (mock)\n",
    "        web = WebSearchTool(api_key=os.getenv(\"TAVILY_API_KEY\", \"test_key\"))\n",
    "        print(\"‚úÖ Web search tool initialized successfully\")\n",
    "        \n",
    "        # Test LLM client\n",
    "        llm = MultiModelLLMClient()\n",
    "        test_response = llm.chat(\"Test connection\", task_type='general')\n",
    "        print(\"‚úÖ LLM client initialized successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during setup: {str(e)}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nüöÄ ODR environment ready!\")\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bdded859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODRAnalytics:\n",
    "    \"\"\"Analytics and reporting for ODR pipeline performance\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session_data = []\n",
    "    \n",
    "    def log_pipeline_execution(self, metadata: Dict[str, Any]):\n",
    "        \"\"\"Log pipeline execution for analytics\"\"\"\n",
    "        self.session_data.append(metadata)\n",
    "    \n",
    "    def generate_session_report(self) -> str:\n",
    "        \"\"\"Generate analytics report for current session\"\"\"\n",
    "        \n",
    "        if not self.session_data:\n",
    "            return \"No pipeline executions recorded in this session.\"\n",
    "        \n",
    "        total_executions = len(self.session_data)\n",
    "        \n",
    "        # Analyze clarification success rate\n",
    "        fully_clarified = sum(1 for data in self.session_data if data.get('fully_clarified', False))\n",
    "        clarification_rate = (fully_clarified / total_executions) * 100\n",
    "        \n",
    "        # Analyze source usage\n",
    "        all_distributions = [data['findings_summary']['source_distribution'] for data in self.session_data]\n",
    "        source_totals = {\"internal\": 0, \"web\": 0, \"hybrid\": 0}\n",
    "        \n",
    "        for dist in all_distributions:\n",
    "            for source, count in dist.items():\n",
    "                source_totals[source] += count\n",
    "        \n",
    "        # Calculate average quality\n",
    "        avg_qualities = [data['findings_summary']['average_quality'] for data in self.session_data]\n",
    "        overall_avg_quality = sum(avg_qualities) / len(avg_qualities)\n",
    "        \n",
    "        report = f\"\"\"\n",
    "# ODR Session Analytics Report\n",
    "\n",
    "## Execution Summary\n",
    "- Total Pipeline Runs: {total_executions}\n",
    "- Successful Clarifications: {fully_clarified}/{total_executions} ({clarification_rate:.1f}%)\n",
    "- Overall Average Quality Score: {overall_avg_quality:.2f}\n",
    "\n",
    "## Data Source Usage\n",
    "- Internal Sources: {source_totals['internal']} sections\n",
    "- Web Search: {source_totals['web']} sections  \n",
    "- Hybrid Approach: {source_totals['hybrid']} sections\n",
    "\n",
    "## Performance Insights\n",
    "- Most commonly used source: {max(source_totals.keys(), key=lambda x: source_totals[x])}\n",
    "- Quality correlation with source type: Hybrid > Internal > Web\n",
    "- Average sections per research: {sum(data['findings_summary']['total_sections'] for data in self.session_data) / total_executions:.1f}\n",
    "        \"\"\"\n",
    "        \n",
    "        return report.strip()\n",
    "\n",
    "class ODRExporter:\n",
    "    \"\"\"Export ODR results in various formats\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_to_markdown(report: str, metadata: Dict[str, Any], filename: str = None) -> str:\n",
    "        \"\"\"Export report to markdown file\"\"\"\n",
    "        \n",
    "        if filename is None:\n",
    "            timestamp = int(time.time())\n",
    "            filename = f\"odr_report_{timestamp}.md\"\n",
    "        \n",
    "        # Add metadata header\n",
    "        markdown_content = f\"\"\"---\n",
    "title: ODR Research Report\n",
    "topic: {metadata['clarified_topic']}\n",
    "generated: {time.ctime(metadata['pipeline_timestamp'])}\n",
    "sections: {metadata['findings_summary']['total_sections']}\n",
    "quality_score: {metadata['findings_summary']['average_quality']:.2f}\n",
    "---\n",
    "\n",
    "{report}\n",
    "\n",
    "---\n",
    "\n",
    "## Report Metadata\n",
    "- **Original Query**: {metadata['original_input']}\n",
    "- **Clarified Topic**: {metadata['clarified_topic']}\n",
    "- **Research Sections**: {metadata['findings_summary']['total_sections']}\n",
    "- **Source Distribution**: {metadata['findings_summary']['source_distribution']}\n",
    "- **Average Quality Score**: {metadata['findings_summary']['average_quality']:.2f}\n",
    "- **Generated**: {time.ctime(metadata['pipeline_timestamp'])}\n",
    "\"\"\"\n",
    "        \n",
    "        # In a real implementation, write to file\n",
    "        print(f\"üìÑ Report exported to {filename}\")\n",
    "        return markdown_content\n",
    "    \n",
    "    @staticmethod\n",
    "    def export_to_json(metadata: Dict[str, Any], filename: str = None) -> str:\n",
    "        \"\"\"Export metadata to JSON file\"\"\"\n",
    "        \n",
    "        if filename is None:\n",
    "            timestamp = int(time.time())\n",
    "            filename = f\"odr_metadata_{timestamp}.json\"\n",
    "        \n",
    "        # Convert research_plan object to dict for JSON serialization\n",
    "        metadata_copy = metadata.copy()\n",
    "        if 'research_plan' in metadata_copy:\n",
    "            plan = metadata_copy['research_plan']\n",
    "            metadata_copy['research_plan'] = {\n",
    "                'topic': plan.topic,\n",
    "                'introduction': plan.introduction,\n",
    "                'sections': plan.sections,\n",
    "                'conclusion': plan.conclusion,\n",
    "                'citations': plan.citations\n",
    "            }\n",
    "        \n",
    "        json_content = json.dumps(metadata_copy, indent=2, default=str)\n",
    "        \n",
    "        print(f\"üìä Metadata exported to {filename}\")\n",
    "        return json_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb877523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interactive_odr():\n",
    "    \"\"\"Create interactive ODR interface for Jupyter notebook\"\"\"\n",
    "    \n",
    "    print(\"üéØ ODR Interactive Research Assistant\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Enter your research topic and let ODR handle the rest!\")\n",
    "    print(\"Type 'quit' to exit, 'help' for commands, 'analytics' for session stats\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Initialize components\n",
    "    odr = ODRPipeline()\n",
    "    analytics = ODRAnalytics()\n",
    "    exporter = ODRExporter()\n",
    "    \n",
    "    # Interactive loop\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\nüîç Enter research topic: \").strip()\n",
    "            \n",
    "            if user_input.lower() == 'quit':\n",
    "                print(\"üëã Goodbye! Thanks for using ODR!\")\n",
    "                break\n",
    "            \n",
    "            elif user_input.lower() == 'help':\n",
    "                print(\"\"\"\n",
    "üìñ ODR Commands:\n",
    "- Enter any research topic to start research\n",
    "- 'analytics' - View session analytics\n",
    "- 'export last' - Export last report to markdown\n",
    "- 'quit' - Exit ODR\n",
    "                \"\"\")\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() == 'analytics':\n",
    "                print(analytics.generate_session_report())\n",
    "                continue\n",
    "            \n",
    "            elif user_input.lower() == 'export last':\n",
    "                if analytics.session_data:\n",
    "                    last_metadata = analytics.session_data[-1]\n",
    "                    # Note: In real implementation, store the actual report\n",
    "                    print(\"üìÑ Last report would be exported here\")\n",
    "                else:\n",
    "                    print(\"‚ùå No reports to export\")\n",
    "                continue\n",
    "            \n",
    "            elif not user_input:\n",
    "                print(\"‚ö†Ô∏è  Please enter a research topic\")\n",
    "                continue\n",
    "            \n",
    "            # Execute ODR pipeline\n",
    "            print(f\"\\nüöÄ Processing: '{user_input}'\")\n",
    "            report, metadata = odr.execute_research_pipeline(user_input)\n",
    "            \n",
    "            # Log for analytics\n",
    "            analytics.log_pipeline_execution(metadata)\n",
    "            \n",
    "            # Display completion message\n",
    "            print(f\"\\n‚úÖ Research completed! Generated {len(report)} characters of content\")\n",
    "            print(f\"üìä Quality Score: {metadata['findings_summary']['average_quality']:.2f}\")\n",
    "            \n",
    "            # Ask if user wants to see the full report\n",
    "            show_report = input(\"\\nüìñ Display full report? (y/n): \").lower().strip()\n",
    "            if show_report == 'y':\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"FINAL RESEARCH REPORT\")\n",
    "                print(\"=\"*60)\n",
    "                print(report)\n",
    "                print(\"=\"*60)\n",
    "        \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\nüëã ODR session interrupted. Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")\n",
    "            print(\"Please try again with a different topic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6eff034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchProcessor:\n",
    "    \"\"\"Process multiple research topics in batch\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.odr = ODRPipeline()\n",
    "        self.results = []\n",
    "    \n",
    "    def process_batch(self, topics: List[str], output_dir: str = \"odr_batch_results\") -> List[Dict]:\n",
    "        \"\"\"Process multiple research topics\"\"\"\n",
    "        \n",
    "        print(f\"üîÑ Starting batch processing of {len(topics)} topics\")\n",
    "        \n",
    "        # Create output directory (simulated)\n",
    "        print(f\"üìÅ Creating output directory: {output_dir}\")\n",
    "        \n",
    "        for i, topic in enumerate(topics, 1):\n",
    "            print(f\"\\nüìñ Processing {i}/{len(topics)}: {topic}\")\n",
    "            \n",
    "            try:\n",
    "                # Execute pipeline\n",
    "                report, metadata = self.odr.execute_research_pipeline(topic)\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    \"topic\": topic,\n",
    "                    \"report\": report,\n",
    "                    \"metadata\": metadata,\n",
    "                    \"status\": \"success\",\n",
    "                    \"processing_order\": i\n",
    "                }\n",
    "                \n",
    "                self.results.append(result)\n",
    "                \n",
    "                # Simulate file writing\n",
    "                filename = f\"report_{i:02d}_{topic.replace(' ', '_')[:30]}.md\"\n",
    "                print(f\"üíæ Saved report to: {filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to process '{topic}': {str(e)}\")\n",
    "                \n",
    "                # Store error result\n",
    "                result = {\n",
    "                    \"topic\": topic,\n",
    "                    \"report\": None,\n",
    "                    \"metadata\": None,\n",
    "                    \"status\": \"error\",\n",
    "                    \"error\": str(e),\n",
    "                    \"processing_order\": i\n",
    "                }\n",
    "                \n",
    "                self.results.append(result)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Batch processing completed!\")\n",
    "        self._generate_batch_summary()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def _generate_batch_summary(self):\n",
    "        \"\"\"Generate summary of batch processing results\"\"\"\n",
    "        \n",
    "        total = len(self.results)\n",
    "        successful = len([r for r in self.results if r[\"status\"] == \"success\"])\n",
    "        failed = total - successful\n",
    "        \n",
    "        print(f\"\\nüìä BATCH PROCESSING SUMMARY\")\n",
    "        print(f\"Total Topics: {total}\")\n",
    "        print(f\"Successful: {successful}\")\n",
    "        print(f\"Failed: {failed}\")\n",
    "        print(f\"Success Rate: {(successful/total)*100:.1f}%\")\n",
    "        \n",
    "        if failed > 0:\n",
    "            print(f\"\\n‚ùå Failed Topics:\")\n",
    "            for result in self.results:\n",
    "                if result[\"status\"] == \"error\":\n",
    "                    print(f\"   - {result['topic']}: {result['error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f037dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function demonstrating ODR capabilities\"\"\"\n",
    "    \n",
    "    print(\"üåü ODR - Organized Data Research System\")\n",
    "    print(\"Advanced AI-Powered Research Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Setup environment\n",
    "    if not setup_environment():\n",
    "        print(\"‚ùå Environment setup failed. Please check configuration.\")\n",
    "        return\n",
    "    \n",
    "    # Example 1: Single Research Execution\n",
    "    print(\"\\nüîç EXAMPLE 1: Single Research Topic\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    odr = ODRPipeline()\n",
    "    sample_topic = \"Impact of quantum computing on encryption standards\"\n",
    "    \n",
    "    try:\n",
    "        report, metadata = odr.execute_research_pipeline(sample_topic)\n",
    "        \n",
    "        print(f\"\\nüìÑ RESEARCH COMPLETED\")\n",
    "        print(f\"Topic: {metadata['clarified_topic']}\")\n",
    "        print(f\"Sections: {metadata['findings_summary']['total_sections']}\")\n",
    "        print(f\"Quality: {metadata['findings_summary']['average_quality']:.2f}\")\n",
    "        \n",
    "        # Show report preview\n",
    "        print(f\"\\nüìñ REPORT PREVIEW:\")\n",
    "        preview = report[:300] + \"...\" if len(report) > 300 else report\n",
    "        print(preview)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in single research: {str(e)}\")\n",
    "    \n",
    "    # Example 2: Batch Processing\n",
    "    print(f\"\\n\\nüîÑ EXAMPLE 2: Batch Processing\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    batch_topics = [\n",
    "        \"AI ethics in autonomous vehicles\",\n",
    "        \"Renewable energy storage solutions\",\n",
    "        \"Blockchain applications in supply chain\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        batch_processor = BatchProcessor()\n",
    "        batch_results = batch_processor.process_batch(batch_topics)\n",
    "        \n",
    "        print(f\"‚úÖ Batch processing demonstration completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in batch processing: {str(e)}\")\n",
    "    \n",
    "    # Example 3: Analytics Demo\n",
    "    print(f\"\\n\\nüìä EXAMPLE 3: Analytics Capabilities\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    analytics = ODRAnalytics()\n",
    "    \n",
    "    # Simulate some session data\n",
    "    for i, topic in enumerate([\"Quantum computing\", \"AI ethics\", \"Climate change\"]):\n",
    "        mock_metadata = {\n",
    "            \"original_input\": topic,\n",
    "            \"clarified_topic\": f\"Advanced analysis of {topic.lower()}\",\n",
    "            \"fully_clarified\": i % 2 == 0,\n",
    "            \"findings_summary\": {\n",
    "                \"total_sections\": 5 + i,\n",
    "                \"source_distribution\": {\"internal\": i, \"web\": 2-i, \"hybrid\": 1},\n",
    "                \"average_quality\": 0.8 + (i * 0.05)\n",
    "            },\n",
    "            \"pipeline_timestamp\": time.time() - (i * 100)\n",
    "        }\n",
    "        analytics.log_pipeline_execution(mock_metadata)\n",
    "    \n",
    "    session_report = analytics.generate_session_report()\n",
    "    print(session_report)\n",
    "    \n",
    "    print(f\"\\nüéØ ODR SYSTEM DEMONSTRATION COMPLETED\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"The system is ready for interactive use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1babe74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåü ODR - Organized Data Research System\n",
      "Advanced AI-Powered Research Pipeline\n",
      "============================================================\n",
      "üîß Setting up ODR environment...\n",
      "‚úÖ All environment variables configured\n",
      "\n",
      "üîå Testing data source connections...\n",
      "‚úÖ MCP tool initialized successfully\n",
      "‚úÖ Web search tool initialized successfully\n",
      "‚úÖ LLM client initialized successfully\n",
      "\n",
      "üöÄ ODR environment ready!\n",
      "\n",
      "üîç EXAMPLE 1: Single Research Topic\n",
      "----------------------------------------\n",
      "üöÄ Starting ODR Pipeline\n",
      "==================================================\n",
      "\n",
      "üìã MODULE 1: User Input Clarification\n",
      "üîç Starting clarification for: 'Impact of quantum computing on encryption standards'\n",
      "\n",
      "üìù Clarification needed (Round 1):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "\n",
      "üìù Clarification needed (Round 2):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "\n",
      "üìù Clarification needed (Round 3):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "‚ö†Ô∏è  Maximum clarification rounds reached. Proceeding with: Impact of quantum computing on current encryption standards: technical capabilities, business implications, and implementation timeline\n",
      "\n",
      "üìä MODULE 2: Research Plan Generation\n",
      "üìã Generating research plan for: Impact of quantum computing on current encryption standards: technical capabilities, business implications, and implementation timeline\n",
      "‚úÖ Research plan generated with 6 sections\n",
      "\n",
      "üìä Research Plan Overview:\n",
      "Introduction: Overview of quantum computing's revolutionary impact on cryptography and data security\n",
      "\n",
      "Sections:\n",
      "  1. Fundamentals of Quantum Computing\n",
      "  2. Current Encryption Standards and Vulnerabilities\n",
      "  3. Quantum Algorithms and Cryptographic Threats\n",
      "  4. Post-Quantum Cryptography Solutions\n",
      "  5. Implementation Challenges and Timeline\n",
      "  6. Industry and Government Response\n",
      "\n",
      "Conclusion Focus: Assessment of the cryptographic landscape transition and future security implications\n",
      "\n",
      "üî¨ MODULE 3: Research Execution\n",
      "üî¨ Starting research execution with 6 sections\n",
      "\n",
      "üìñ Researching Section 1: Fundamentals of Quantum Computing\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 2: Current Encryption Standards and Vulnerabilities\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 3: Quantum Algorithms and Cryptographic Threats\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 4: Post-Quantum Cryptography Solutions\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 5: Implementation Challenges and Timeline\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 6: Industry and Government Response\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "‚úÖ Research completed for all 6 sections\n",
      "\n",
      "üìù FINAL STEP: Report Generation\n",
      "üìù Generating final research report...\n",
      "‚úÖ Final report generated successfully\n",
      "\n",
      "‚úÖ ODR Pipeline completed successfully!\n",
      "==================================================\n",
      "\n",
      "üìÑ RESEARCH COMPLETED\n",
      "Topic: Impact of quantum computing on current encryption standards: technical capabilities, business implications, and implementation timeline\n",
      "Sections: 6\n",
      "Quality: 0.81\n",
      "\n",
      "üìñ REPORT PREVIEW:\n",
      "# Quantum Computing and Encryption: A Comprehensive Analysis\n",
      "\n",
      "## Introduction\n",
      "Quantum computing represents one of the most significant technological advances of the 21st century, with profound implications for digital security and cryptography. As quantum computers evolve from theoretical concepts t...\n",
      "\n",
      "\n",
      "üîÑ EXAMPLE 2: Batch Processing\n",
      "----------------------------------------\n",
      "üîÑ Starting batch processing of 3 topics\n",
      "üìÅ Creating output directory: odr_batch_results\n",
      "\n",
      "üìñ Processing 1/3: AI ethics in autonomous vehicles\n",
      "üöÄ Starting ODR Pipeline\n",
      "==================================================\n",
      "\n",
      "üìã MODULE 1: User Input Clarification\n",
      "üîç Starting clarification for: 'AI ethics in autonomous vehicles'\n",
      "\n",
      "üìù Clarification needed (Round 1):\n",
      "   1. Are you interested in AI ethics in healthcare, autonomous vehicles, or general applications?\n",
      "   2. Do you want to focus on current ethical frameworks or emerging challenges?\n",
      "   3. What specific aspects: bias, privacy, accountability, or transparency?\n",
      "\n",
      "üìù Clarification needed (Round 2):\n",
      "   1. Are you interested in AI ethics in healthcare, autonomous vehicles, or general applications?\n",
      "   2. Do you want to focus on current ethical frameworks or emerging challenges?\n",
      "   3. What specific aspects: bias, privacy, accountability, or transparency?\n",
      "\n",
      "üìù Clarification needed (Round 3):\n",
      "   1. Are you interested in AI ethics in healthcare, autonomous vehicles, or general applications?\n",
      "   2. Do you want to focus on current ethical frameworks or emerging challenges?\n",
      "   3. What specific aspects: bias, privacy, accountability, or transparency?\n",
      "‚ö†Ô∏è  Maximum clarification rounds reached. Proceeding with: AI ethics in autonomous vehicles - General AI applications across industries, Current ethical frameworks and emerging challenges - General AI applications across industries, Current ethical frameworks and emerging challenges - General AI applications across industries, Current ethical frameworks and emerging challenges\n",
      "\n",
      "üìä MODULE 2: Research Plan Generation\n",
      "üìã Generating research plan for: AI ethics in autonomous vehicles - General AI applications across industries, Current ethical frameworks and emerging challenges - General AI applications across industries, Current ethical frameworks and emerging challenges - General AI applications across industries, Current ethical frameworks and emerging challenges\n",
      "‚úÖ Research plan generated with 4 sections\n",
      "\n",
      "üìä Research Plan Overview:\n",
      "Introduction: Comprehensive analysis of the research topic\n",
      "\n",
      "Sections:\n",
      "  1. Background\n",
      "  2. Current State\n",
      "  3. Analysis\n",
      "  4. Implications\n",
      "\n",
      "Conclusion Focus: Summary of findings and future considerations\n",
      "\n",
      "üî¨ MODULE 3: Research Execution\n",
      "üî¨ Starting research execution with 4 sections\n",
      "\n",
      "üìñ Researching Section 1: Background\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 2: Current State\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 3: Analysis\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 4: Implications\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "‚úÖ Research completed for all 4 sections\n",
      "\n",
      "üìù FINAL STEP: Report Generation\n",
      "üìù Generating final research report...\n",
      "‚úÖ Final report generated successfully\n",
      "\n",
      "‚úÖ ODR Pipeline completed successfully!\n",
      "==================================================\n",
      "üíæ Saved report to: report_01_AI_ethics_in_autonomous_vehicl.md\n",
      "\n",
      "üìñ Processing 2/3: Renewable energy storage solutions\n",
      "üöÄ Starting ODR Pipeline\n",
      "==================================================\n",
      "\n",
      "üìã MODULE 1: User Input Clarification\n",
      "üîç Starting clarification for: 'Renewable energy storage solutions'\n",
      "\n",
      "üìù Clarification needed (Round 1):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "\n",
      "üìù Clarification needed (Round 2):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "\n",
      "üìù Clarification needed (Round 3):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "‚ö†Ô∏è  Maximum clarification rounds reached. Proceeding with: Renewable energy storage solutions - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments\n",
      "\n",
      "üìä MODULE 2: Research Plan Generation\n",
      "üìã Generating research plan for: Renewable energy storage solutions - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments\n",
      "‚úÖ Research plan generated with 4 sections\n",
      "\n",
      "üìä Research Plan Overview:\n",
      "Introduction: Comprehensive analysis of the research topic\n",
      "\n",
      "Sections:\n",
      "  1. Background\n",
      "  2. Current State\n",
      "  3. Analysis\n",
      "  4. Implications\n",
      "\n",
      "Conclusion Focus: Summary of findings and future considerations\n",
      "\n",
      "üî¨ MODULE 3: Research Execution\n",
      "üî¨ Starting research execution with 4 sections\n",
      "\n",
      "üìñ Researching Section 1: Background\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 2: Current State\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 3: Analysis\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 4: Implications\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "‚úÖ Research completed for all 4 sections\n",
      "\n",
      "üìù FINAL STEP: Report Generation\n",
      "üìù Generating final research report...\n",
      "‚úÖ Final report generated successfully\n",
      "\n",
      "‚úÖ ODR Pipeline completed successfully!\n",
      "==================================================\n",
      "üíæ Saved report to: report_02_Renewable_energy_storage_solut.md\n",
      "\n",
      "üìñ Processing 3/3: Blockchain applications in supply chain\n",
      "üöÄ Starting ODR Pipeline\n",
      "==================================================\n",
      "\n",
      "üìã MODULE 1: User Input Clarification\n",
      "üîç Starting clarification for: 'Blockchain applications in supply chain'\n",
      "\n",
      "üìù Clarification needed (Round 1):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "\n",
      "üìù Clarification needed (Round 2):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "\n",
      "üìù Clarification needed (Round 3):\n",
      "   1. Could you provide more specific details about what aspects you'd like to research?\n",
      "   2. What is the intended use or audience for this research?\n",
      "   3. Are there any particular angles or perspectives you want to focus on?\n",
      "‚ö†Ô∏è  Maximum clarification rounds reached. Proceeding with: Blockchain applications in supply chain - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments\n",
      "\n",
      "üìä MODULE 2: Research Plan Generation\n",
      "üìã Generating research plan for: Blockchain applications in supply chain - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments - Provide comprehensive coverage, Include recent developments\n",
      "‚úÖ Research plan generated with 4 sections\n",
      "\n",
      "üìä Research Plan Overview:\n",
      "Introduction: Comprehensive analysis of the research topic\n",
      "\n",
      "Sections:\n",
      "  1. Background\n",
      "  2. Current State\n",
      "  3. Analysis\n",
      "  4. Implications\n",
      "\n",
      "Conclusion Focus: Summary of findings and future considerations\n",
      "\n",
      "üî¨ MODULE 3: Research Execution\n",
      "üî¨ Starting research execution with 4 sections\n",
      "\n",
      "üìñ Researching Section 1: Background\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 2: Current State\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 3: Analysis\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "üìñ Researching Section 4: Implications\n",
      "   üéØ Selected source: internal_mcp (confidence: 0.85)\n",
      "   üìù Reasoning: Internal data sources contain relevant recent analysis on this topic\n",
      "   üè† Using internal data sources...\n",
      "\n",
      "‚úÖ Research completed for all 4 sections\n",
      "\n",
      "üìù FINAL STEP: Report Generation\n",
      "üìù Generating final research report...\n",
      "‚úÖ Final report generated successfully\n",
      "\n",
      "‚úÖ ODR Pipeline completed successfully!\n",
      "==================================================\n",
      "üíæ Saved report to: report_03_Blockchain_applications_in_sup.md\n",
      "\n",
      "‚úÖ Batch processing completed!\n",
      "\n",
      "üìä BATCH PROCESSING SUMMARY\n",
      "Total Topics: 3\n",
      "Successful: 3\n",
      "Failed: 0\n",
      "Success Rate: 100.0%\n",
      "‚úÖ Batch processing demonstration completed\n",
      "\n",
      "\n",
      "üìä EXAMPLE 3: Analytics Capabilities\n",
      "----------------------------------------\n",
      "# ODR Session Analytics Report\n",
      "\n",
      "## Execution Summary\n",
      "- Total Pipeline Runs: 3\n",
      "- Successful Clarifications: 2/3 (66.7%)\n",
      "- Overall Average Quality Score: 0.85\n",
      "\n",
      "## Data Source Usage\n",
      "- Internal Sources: 3 sections\n",
      "- Web Search: 3 sections  \n",
      "- Hybrid Approach: 3 sections\n",
      "\n",
      "## Performance Insights\n",
      "- Most commonly used source: internal\n",
      "- Quality correlation with source type: Hybrid > Internal > Web\n",
      "- Average sections per research: 6.0\n",
      "\n",
      "üéØ ODR SYSTEM DEMONSTRATION COMPLETED\n",
      "============================================================\n",
      "The system is ready for interactive use!\n",
      "\n",
      "üöÄ ODR System loaded successfully!\n",
      "üìñ Available functions:\n",
      "   - main(): Complete system demonstration\n",
      "   - create_interactive_odr(): Interactive research assistant\n",
      "   - run_odr_demo(): Quick demo with test cases\n",
      "   - setup_environment(): Check environment configuration\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Option 1: Run full demonstration\n",
    "    main()\n",
    "    \n",
    "    # Option 2: Start interactive mode (uncomment to use)\n",
    "    # create_interactive_odr()\n",
    "    \n",
    "    # Option 3: Run specific demo (uncomment to use)\n",
    "    # run_odr_demo()\n",
    "\n",
    "print(\"\\nüöÄ ODR System loaded successfully!\")\n",
    "print(\"üìñ Available functions:\")\n",
    "print(\"   - main(): Complete system demonstration\")\n",
    "print(\"   - create_interactive_odr(): Interactive research assistant\")\n",
    "print(\"   - run_odr_demo(): Quick demo with test cases\")\n",
    "print(\"   - setup_environment(): Check environment configuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b8fb91a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_research_plan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[91]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgenerate_research_plan\u001b[49m(clarified_topic)\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_research_plan' is not defined"
     ]
    }
   ],
   "source": [
    "generate_research_plan(clarified_topic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15f87864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'The Impact of Quantum Computing on Encryption Standards', 'Introduction': 'This section introduces the basics of encryption and quantum computing...', 'Section 1': 'Current encryption standards like RSA and ECC...', 'Section 2': 'How quantum computers threaten these standards...', 'Section 3': 'Post-quantum cryptographic alternatives...', 'Conclusion': 'Quantum computing poses serious risks to current encryption...', 'References': ['NIST PQC Project', \"Shor's Algorithm Paper\"]}\n"
     ]
    }
   ],
   "source": [
    "clarified_topic = {\n",
    "    \"topic\": \"Impact of quantum computing on encryption standards\",\n",
    "    \"scope\": \"Focus on how quantum computing challenges current encryption standards like RSA and ECC\",\n",
    "    \"audience\": \"Cybersecurity researchers and policy makers\",\n",
    "    \"angle\": \"Future-proofing cryptographic systems using post-quantum cryptography\"\n",
    "}\n",
    "def generate_research_plan(clarified_topic):\n",
    "    return {\n",
    "        \"Title\": f\"The Impact of Quantum Computing on Encryption Standards\",\n",
    "        \"Introduction\": \"This section introduces the basics of encryption and quantum computing...\",\n",
    "        \"Section 1\": \"Current encryption standards like RSA and ECC...\",\n",
    "        \"Section 2\": \"How quantum computers threaten these standards...\",\n",
    "        \"Section 3\": \"Post-quantum cryptographic alternatives...\",\n",
    "        \"Conclusion\": \"Quantum computing poses serious risks to current encryption...\",\n",
    "        \"References\": [\"NIST PQC Project\", \"Shor's Algorithm Paper\"]\n",
    "    }\n",
    "\n",
    "research_plan = generate_research_plan(clarified_topic)\n",
    "print(research_plan)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf4d1fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìò Researching section: Title\n",
      "\n",
      "üìò Researching section: Introduction\n",
      "üåê Using web search\n",
      "\n",
      "üìò Researching section: Section 1\n",
      "üåê Using web search\n",
      "\n",
      "üìò Researching section: Section 2\n",
      "üåê Using web search\n",
      "\n",
      "üìò Researching section: Section 3\n",
      "üåê Using web search\n",
      "\n",
      "üìò Researching section: Conclusion\n",
      "üåê Using web search\n",
      "\n",
      "üìò Researching section: References\n",
      "\n",
      "üîπ Title:\n",
      "The Impact of Quantum Computing on Encryption Standards\n",
      "\n",
      "üîπ Introduction:\n",
      "üîç Generated content based on: Web search results for: This section introduces the basics of encryption and quantum computing...\n",
      "\n",
      "üîπ Section 1:\n",
      "üîç Generated content based on: Web search results for: Current encryption standards like RSA and ECC...\n",
      "\n",
      "üîπ Section 2:\n",
      "üîç Generated content based on: Web search results for: How quantum computers threaten these standards...\n",
      "\n",
      "üîπ Section 3:\n",
      "üîç Generated content based on: Web search results for: Post-quantum cryptographic alternatives...\n",
      "\n",
      "üîπ Conclusion:\n",
      "üîç Generated content based on: Web search results for: Quantum computing poses serious risks to current encryption...\n",
      "\n",
      "üîπ References:\n",
      "['NIST PQC Project', \"Shor's Algorithm Paper\"]\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Module 3: Research Execution ------------------\n",
    "\n",
    "# Dummy MCP tool that checks internal knowledge base (replace with your own logic)\n",
    "class MockMCPTool:\n",
    "    def query(self, query_text):\n",
    "        # Simulate that internal data is missing for now\n",
    "        return None  # Replace with actual lookup logic\n",
    "\n",
    "# Dummy Web Search tool using Tavily (replace with your real implementation)\n",
    "class MockWebSearchTool:\n",
    "    def search(self, query_text):\n",
    "        # Simulated search results\n",
    "        return f\"Web search results for: {query_text}\"\n",
    "\n",
    "# Dummy LLM client that generates research content from search results\n",
    "class MockLLMClient:\n",
    "    def summarize(self, search_result):\n",
    "        return f\"üîç Generated content based on: {search_result}\"\n",
    "\n",
    "# SupervisorAgent that chooses between internal data or web search\n",
    "class SupervisorAgent:\n",
    "    def __init__(self, llm_client, mcp_tool, websearch_tool):\n",
    "        self.llm_client = llm_client\n",
    "        self.mcp_tool = mcp_tool\n",
    "        self.websearch_tool = websearch_tool\n",
    "\n",
    "    def execute_research_plan(self, plan):\n",
    "        section_outputs = {}\n",
    "        for section_title, summary in plan.items():\n",
    "            print(f\"\\nüìò Researching section: {section_title}\")\n",
    "\n",
    "            # Skip non-section metadata like \"Title\"\n",
    "            if section_title.lower() in [\"title\", \"references\"]:\n",
    "                section_outputs[section_title] = summary\n",
    "                continue\n",
    "\n",
    "            # Try internal data first\n",
    "            internal_data = self.mcp_tool.query(summary)\n",
    "            if internal_data:\n",
    "                print(\"‚úÖ Found internal data\")\n",
    "                section_outputs[section_title] = internal_data\n",
    "                continue\n",
    "\n",
    "            # If no internal data, fallback to web\n",
    "            print(\"üåê Using web search\")\n",
    "            search_results = self.websearch_tool.search(summary)\n",
    "            content = self.llm_client.summarize(search_results)\n",
    "            section_outputs[section_title] = content\n",
    "\n",
    "        return section_outputs\n",
    "\n",
    "\n",
    "# --- Initialize Mock Tools (Replace these with your real ones if available) ---\n",
    "mcp_tool = MockMCPTool()\n",
    "websearch_tool = MockWebSearchTool()\n",
    "llm_client = MockLLMClient()\n",
    "\n",
    "# Initialize supervisor agent\n",
    "supervisor = SupervisorAgent(llm_client, mcp_tool, websearch_tool)\n",
    "\n",
    "# Execute research\n",
    "section_outputs = supervisor.execute_research_plan(research_plan)\n",
    "\n",
    "# Print the research content\n",
    "for section, content in section_outputs.items():\n",
    "    print(f\"\\nüîπ {section}:\\n{content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6f3335bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The Impact of Quantum Computing on Encryption Standards\n",
      "\n",
      "## Introduction\n",
      "üîç Generated content based on: Web search results for: This section introduces the basics of encryption and quantum computing...\n",
      "\n",
      "## Section 1\n",
      "üîç Generated content based on: Web search results for: Current encryption standards like RSA and ECC...\n",
      "\n",
      "## Section 2\n",
      "üîç Generated content based on: Web search results for: How quantum computers threaten these standards...\n",
      "\n",
      "## Section 3\n",
      "üîç Generated content based on: Web search results for: Post-quantum cryptographic alternatives...\n",
      "\n",
      "## Conclusion\n",
      "üîç Generated content based on: Web search results for: Quantum computing poses serious risks to current encryption...\n",
      "\n",
      "## References\n",
      "- NIST PQC Project\n",
      "- Shor's Algorithm Paper\n",
      "\n",
      "\n",
      "üìò (Polished by writing model)\n"
     ]
    }
   ],
   "source": [
    "# ------------------ Module 4: Report Generation ------------------\n",
    "\n",
    "# Optional: Use a writing-focused model to polish the entire report\n",
    "class MockWritingModel:\n",
    "    def polish(self, text):\n",
    "        # Simulate polish ‚Äî replace with your actual LLM (e.g., Claude, GPT-4, etc.)\n",
    "        return text + \"\\n\\nüìò (Polished by writing model)\"\n",
    "\n",
    "def generate_report_from_sections(section_outputs, research_plan, writer_model=None):\n",
    "    report = []\n",
    "\n",
    "    # Add the title\n",
    "    title = section_outputs.get(\"Title\", research_plan.get(\"Title\", \"Untitled Research Report\"))\n",
    "    report.append(f\"# {title}\\n\")\n",
    "\n",
    "    # Add Introduction\n",
    "    intro = section_outputs.get(\"Introduction\", \"\")\n",
    "    report.append(f\"## Introduction\\n{intro}\\n\")\n",
    "\n",
    "    # Add body sections\n",
    "    for i in range(1, 10):  # Assume max 10 sections\n",
    "        section_key = f\"Section {i}\"\n",
    "        if section_key in section_outputs:\n",
    "            content = section_outputs[section_key]\n",
    "            report.append(f\"## {section_key}\\n{content}\\n\")\n",
    "\n",
    "    # Add Conclusion\n",
    "    conclusion = section_outputs.get(\"Conclusion\", \"\")\n",
    "    report.append(f\"## Conclusion\\n{conclusion}\\n\")\n",
    "\n",
    "    # Add References\n",
    "    references = section_outputs.get(\"References\", [])\n",
    "    if isinstance(references, list):\n",
    "        ref_text = \"\\n\".join([f\"- {ref}\" for ref in references])\n",
    "    else:\n",
    "        ref_text = references\n",
    "    report.append(f\"## References\\n{ref_text}\\n\")\n",
    "\n",
    "    # Combine everything\n",
    "    final_text = \"\\n\".join(report)\n",
    "\n",
    "    # Optionally polish with writing-focused model\n",
    "    if writer_model:\n",
    "        final_text = writer_model.polish(final_text)\n",
    "\n",
    "    return final_text\n",
    "\n",
    "\n",
    "# Optional: Use writing model to refine the result\n",
    "writer_model = MockWritingModel()\n",
    "\n",
    "# Generate final report\n",
    "final_report = generate_report_from_sections(section_outputs, research_plan, writer_model)\n",
    "\n",
    "# Display it\n",
    "print(final_report)\n",
    "\n",
    "# Optional: Save to file\n",
    "with open(\"ODR_Final_Report.md\", \"w\") as f:\n",
    "    f.write(final_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "45910f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The Impact of Quantum Computing on Encryption Standards\n",
      "\n",
      "## Introduction\n",
      "üîç Generated content based on: Web search results for: This section introduces the basics of encryption and quantum computing...\n",
      "\n",
      "## Section 1\n",
      "üîç Generated content based on: Web search results for: Current encryption standards like RSA and ECC...\n",
      "\n",
      "## Section 2\n",
      "üîç Generated content based on: Web search results for: How quantum computers threaten these standards...\n",
      "\n",
      "## Section 3\n",
      "üîç Generated content based on: Web search results for: Post-quantum cryptographic alternatives...\n",
      "\n",
      "## Conclusion\n",
      "üîç Generated content based on: Web search results for: Quantum computing poses serious risks to current encryption...\n",
      "\n",
      "## References\n",
      "- NIST PQC Project\n",
      "- Shor's Algorithm Paper\n",
      "\n",
      "\n",
      "üìò (Polished by writing model)\n"
     ]
    }
   ],
   "source": [
    "print(final_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc27f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
